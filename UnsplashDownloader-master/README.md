# 使用方法
首先下载Scrapy。

```
pip install scrapy
```
然后到项目内配置数据库文件目录。

最后在项目根目录下输入以下命令即可开始爬虫。

```
scrapy crawl UnsplashSpider
```
爬到的下载地址将放在数据库中。再输入以下命令即可读取数据库并下载文件。

```
Python PengDownloader.py
```


# 关于这个项目
关于这个项目有一篇文章。[见我的知乎专栏](https://zhuanlan.zhihu.com/p/24855089)

# 百度云下载地址

链接: https://pan.baidu.com/s/1c21wM6c 密码: bvuu

注：爬取时间为2017年1月12日
